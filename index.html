<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
    />
    <title>가상여친</title>
    <link rel="stylesheet" href="dist/reset.css" />
    <link rel="stylesheet" href="dist/reveal.css" />
    <link rel="stylesheet" href="dist/theme/black.css" />
    <link rel="stylesheet" href="plugin/highlight/monokai.css" />
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section>
          <h4>가상의 AI 여친</h4>
          <img data-src="dist/assets/ai_girlfriend.png" style="height: 400px" />
        </section>

        <section data-transition="slide">
          <h2>개요</h2>
        </section>
        <section data-transition="slide">
          <h4>데모 영상</h4>
          <video data-autoplay src="dist/assets/demo.mp4"></video>
        </section>
        <section data-transition="slide">
          <h4>사용 스택 및 기술</h4>
          <ul>
            <li style="font-size: 25px">
              프론트엔드 - React, Threejs, Tailwindcss, Zustand
            </li>
            <li style="font-size: 25px">벡엔드 - Python, FastAPI</li>
            <li style="font-size: 25px">OpenAI 파이썬 패키지</li>
            <ul>
              <li style="font-size: 25px">
                OpenAI에서는 OpenAI에서 개발한 인공지능 모델을 쉽게 사용할 수
                있도록 파이썬 OpenAI 패키지를 제공하고 있습니다.
              </li>
            </ul>
            <li style="font-size: 25px">Azure Speech SDK</li>
            <ul>
              <li style="font-size: 25px">
                Azure Speech SDK는 텍스트 음성 변환(text-to-speech) 등과 같은
                많은 Speech Services 기능을 제공하므로 음성 지원 애플리케이션을
                개발할 수 있습니다.
              </li>
            </ul>
          </ul>
        </section>

        <section data-transition="slide">
          <h2>3D 아바타 및 애니메이션 준비</h2>
        </section>
        <section data-transition="slide">
          <h4>ReadyPlayerMe 3D 아바타</h4>
          <img data-src="dist/assets/avatar.png" style="height: 400px" />
          <ul>
            <li style="font-size: 25px">
              Ready Player Me는 여러 종류의 컴퓨터 플랫폼에서 동작할 수 있는 3D
              아바타 생성 서비스로서 캐릭터를 구축하는데 오랜 시간을 소비하지
              않고도 서비스 내의 에디터를 통해서 빠르게 3D 캐릭터를 생성하고
              다양한 플랫폼에서 바로 활용할 수 있습니다.
            </li>
          </ul>
        </section>
        <section data-transition="slide">
          <h4>ReadyPlayerMe 3D 아바타</h4>
          <img data-src="dist/assets/morphTargets.png" style="height: 300px" />
          <ul>
            <li style="font-size: 25px">
              ReadyPlayerMe는 Oculus LipSync API와 호환되는 다양한 립싱크 입모양
              blendshape 뿐만 아니라 Apple ARKit과 호환되는 다양한 얼굴 표정
              blendshape을 지원합니다.
            </li>
            <li style="font-size: 25px">
              조정가능한 다양한 얼굴 표정과 립싱크 입모양 blendshape 값들을 갖춘
              3D 아바타를 다운로드하려면 morphTargets이란 쿼리 파리미터로 설정할
              수 있습니다.
            </li>
            <li style="font-size: 25px">
              예)
              https://models.readyplayer.me/65a8dba831b23abb4f401bae.glb?morphTargets=ARKit,Oculus
              Visemes
            </li>
          </ul>
        </section>
        <section data-transition="slide">
          <h4>Mixamo 애니메이션</h4>
          <img data-src="dist/assets/mixamo.png" style="height: 400px" />
          <ul>
            <li style="font-size: 25px">
              가상의 AI 여친이 응답할 때 좀 더 입체적이고 생동적인 느낌을 주기
              위해 다양한 애니메이션이 필요했습니다. 직접 애니메이션을
              만들기에는 많은 시간이 걸리므로 대신 수천 개의 애니메이션을 무로료
              제공하는 Mixamo라는 서비스를 활용했습니다.
            </li>
          </ul>
        </section>
        <section data-transition="slide">
          <h4>Mixamo 애니메이션</h4>
          <img
            data-src="dist/assets/packing_animations.png"
            style="height: 400px"
          />
          <ul>
            <li style="font-size: 25px">
              Blender 프로그램으로 Mixamo에서 다운로드한 여러 개의 애니메이션을
              packing하여 하나의 glb 파일로 export했습니다.
            </li>
          </ul>
        </section>

        <section data-transition="slide">
          <h2>벡엔드 API</h2>
        </section>
        <section data-transition="slide">
          <h4>API 엔드포인트</h4>
          <table style="font-size: 25px">
            <thead>
              <tr>
                <th>HTTP 메서드</th>
                <th>URL(자원)</th>
                <th>엔드포인트의 행위</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>POST</td>
                <td>/api/chats/?question=</td>
                <td>
                  새로운 채팅을 생성하여 질문을 입력으로 받아 OpenAI 모델이
                  생성한 메시지를 반환
                </td>
              </tr>
              <tr>
                <td>GET</td>
                <td>/api/tts/?text=</td>
                <td>
                  OpenAI가 응답한 메세지의 텍스트를 입력으로 받고 음성으로
                  변환하여 응답
                </td>
              </tr>
            </tbody>
          </table>
        </section>
        <section data-transition="slide">
          <h4>chats 엔드포인트</h4>
          <pre><code class="hljs python" data-trim data-line-numbers="4|28-54" style="font-size: 15px;">
            from typing import List
            from fastapi import APIRouter
            from pydantic import BaseModel
            from openai import OpenAI
            import json

            from app.core import config

            client = OpenAI(api_key=config.OPENAI_API_KEY)

            router = APIRouter()


            class MessagePublic(BaseModel):
                text: str
                facialExpression: str
                animation: str


            @router.post("/")
            async def create_new_chat(question: str) -> List[MessagePublic]:
                completion = client.chat.completions.create(
                    model="gpt-4o-mini",
                    max_tokens=1000,
                    temperature=0.6,
                    response_format={"type": "json_object"},
                    messages=[
                        {
                            "role": "system",
                            "content": """
                              넌 나의 가상의 여자친구야. 나는 너의 남자친구이므로 격식없는 편한 대화체로 대답해야해. 
                              
                              반드시 JSON 객체로 응답해야해.
                              messages라는 필드는 JSON 배열이고, 최대 3개야. 
                              각각의 메시지는 text, facialExpression 그리고 animation 속성이 있어.
                              facialExpression과 animation은 최대한 text의 내용과 관련있는 것으로 골라야해.
                              
                              facialExpression은 반드시 아래의 값들 중에서 선택해야해. 
                              - default
                              - smile
                              - sad
                              - surprised
                              - funny
                              
                              animation은 반드시 아래의 값들 중에서 선택해야해.
                              - Talking In General Conversation
                              - Talking And Finding Something Funny
                              - Asking A Question
                              - Being Bashful
                              - Being Thankful
                              - Hip Hop Dancing
                              - Angry Gesture
                            """,
                        },
                        {
                            "role": "user",
                            "content": question,
                        },
                    ],
                )

                content = json.loads(completion.choices[0].message.content)

                messages = content["messages"]

                return [MessagePublic(**l) for l in messages]
          </code></pre>
          <ul>
            <li style="font-size: 25px">
              OpenAI에서는 OpenAI에서 개발한 인공지능 모델을 쉽게 사용할 수
              있도록 파이썬 OpenAI 패키지를 제공하고 있습니다.
            </li>
            <li style="font-size: 25px">
              프롬프트 엔지니어링을 통해 system 즉 AI의 역할을 명시하고 어떤
              방식으로 응답해야 하는지 설정했습니다.
            </li>
          </ul>
        </section>
        <section data-transition="slide">
          <h2>응답 예시</h2>
          <ul>
            <li style="font-size: 25px">
              /api/chats/?question=내 고양이 메롱이가 아프지 않았으면 좋겠어...
            </li>
            <li style="font-size: 25px">
              <pre><code class="hljs json" data-trim style="font-size: 15px;">
                [
                  {
                    "text": "메롱이가 아프지 않길 진짜 바래! 고양이들은 아플 때 많이 힘들어하니까.",
                    "facialExpression": "sad",
                    "animation": "Talking In General Conversation"
                  },
                  {
                    "text": "혹시 아프면 바로 병원 데려가야 해! 건강이 제일 중요하니까.",
                    "facialExpression": "default",
                    "animation": "Asking A Question"
                  },
                  {
                    "text": "메롱이가 빨리 나아지길 기도할게! 함께 응원하자!",
                    "facialExpression": "smile",
                    "animation": "Being Thankful"
                  }
                ]
              </code></pre>
            </li>
          </ul>
        </section>
        <section data-transition="slide">
          <h4>tts 엔드포인트</h4>
          <pre><code class="hljs python" data-trim data-line-numbers="3|29-35|40-49" style="font-size: 15px;">
            from typing import List
            from fastapi import APIRouter, Response
            import azure.cognitiveservices.speech as speechsdk
            import json
            
            from app.core import config
            
            
            router = APIRouter()
            
            
            @router.get("/")
            async def get_tts(text: str):
                # Define configurations for speech synthesis
                speech_config = speechsdk.SpeechConfig(
                    subscription=config.SPEECH_KEY,
                    region=config.SPEECH_REGION,
                )
            
                # Specify the voice of speech_config to match your input text
                speech_config.speech_synthesis_voice_name = "ko-KR-SoonBokNeural"
            
                # Create a SpeechSynthesizer object.
                speech_synthesizer = speechsdk.SpeechSynthesizer(
                    speech_config=speech_config,
                    audio_config=None,
                )
            
                visemes = []
            
                def viseme_cb(evt):
                    visemes.append([evt.audio_offset / 10000, evt.viseme_id])
            
                # Subscribes to viseme received event
                speech_synthesizer.viseme_received.connect(viseme_cb)
            
                # Synthesize speech
                speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()
            
                return Response(
                    content=speech_synthesis_result.audio_data,
                    headers={
                        "Content-Type": "audio/mpeg",
                        "Content-Disposition": 'inline; filename="tts.mp3"',
                        # send additional data in headers
                        "Visemes": json.dumps(visemes),
                    },
                    media_type="audio/mpeg",
                )            
          </code></pre>
          <ul>
            <li style="font-size: 25px">
              AI 응답을 음성으로 변환하기 위해 Azure Speech SDK를 활용했습니다.
            </li>
            <li style="font-size: 25px">
              Visemes 정보를 활용해 립싱크 구현했습니다. (visemes이란 음소의
              시각적 설명으로서 사람이 말하는 동안 얼굴과 입의 위치를
              정의합니다)
            </li>
            <li style="font-size: 25px">
              파일을 직접 다운로드하는 것이 아니라 웹페이지 내부에서 표시될 수
              있도록 설정하기 위해 Content-Disposition을 inline으로
              설정했습니다.
            </li>
          </ul>
        </section>

        <section data-transition="slide">
          <h2>프론트엔드</h2>
        </section>
        <section data-transition="slide">
          <h4>R3F(React Three Fiber)</h4>
          <img data-src="dist/assets/r3f.jpg" style="height: 400px" />
          <ul>
            <li style="font-size: 25px">
              Three.js를 React에서 사용하기 쉽도록 wrapping된 라이브러리로서
              React에서 Three.js를 사용하기 편리합니다.
            </li>
          </ul>
        </section>
        <section data-transition="slide">
          <h4>Zustand 상태관리</h4>
          <img data-src="dist/assets/zustand.png" style="height: 400px" />
          <ul>
            <li style="font-size: 25px">
              HTML 컴포넌트와 3D 컴포넌트 간에 데이터 상태를 공유하고 API 로직을
              한곳에 두고 전역적으로 관리하기 위해 zustand를 상태관리
              라이브러리로 사용했습니다.
            </li>
            <li style="font-size: 25px">
              Redux 비해 훨씬 가볍고 보일러플레이트도 많이 줄어들어서 전체적으로
              코드가 간결해졌습니다.
            </li>
          </ul>
        </section>

        <section data-transition="slide">
          <h2>다음 단계...</h2>
          <ul>
            <li style="font-size: 25px">
              현재는 Azure Speech SDK에서 제공하는 pre-built 음성을 활용하고
              있지만 음성의 스타일 및 역할을 커스터마이징하기 위해 custom neural
              voice를 만들예정입니다.
            </li>
            <li style="font-size: 25px">
              사용자가 원하는 여친 아바타 중 하나를 선택할 수 있도록 여러 개의
              아바타를 추가할 예정입니다.
            </li>
          </ul>
        </section>

        <section data-transition="slide">
          <h2>링크</h2>
          <p>
            <small
              ><a
                href="https://github.com/dillabadu2138/ai-girlfriend"
                target="_blank"
                >GitHub 링크</a
              >를 첨부했습니다.</small
            >
          </p>
        </section>
      </div>
    </div>
    <script src="dist/reveal.js"></script>
    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>
    <script>
      // More info about initialization & config:
      // - https://revealjs.com/initialization/
      // - https://revealjs.com/config/
      Reveal.initialize({
        hash: true,
        slideNumber: "c/t",
        autoPlayMedia: true,
        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [RevealMarkdown, RevealHighlight, RevealNotes],
      });
    </script>
  </body>
</html>
